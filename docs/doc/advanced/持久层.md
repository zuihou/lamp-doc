---
title: 持久层
index: false
category:
  - 开发进阶
tag:
  - 开发进阶
  - 持久层
---

## 修改P6Spy打印的SQL语句参数和输出格式

::: tip

lamp-cloud-pro-column或lamp-boot-pro-column项目，使用oracle时，不支持使用p6spy来打印SQL语句。请参考：[常用配置](/doc/advanced/tenant/常用配置.html)

:::

::: code-tabs

@tab spy.properties

```properties
# 自定义日志打印
logMessageFormat=top.tangyh.basic.database.p6spy.TenantP6SpyLogger
```

@tab TenantP6SpyLogger

```java
package top.tangyh.basic.database.p6spy;
public class TenantP6SpyLogger implements MessageFormattingStrategy {
    public static final String REGX = "\\s+";

    @Override
    public String formatMessage(int connectionId, String now, long elapsed, String category,
                                String prepared, String sql, String url) {
      	// 返回值是啥，控制台打印SQL语句的格式就是啥
        return StringUtils.isNotBlank(sql) ?
                StrUtil.format("{}: {} {}: {} {}: {} \n Consume Time：{} ms {} \n url: {} \n Execute SQL：{} \n",
                        ContextConstants.TENANT_BASE_POOL_NAME_HEADER, ContextUtil.getBasePoolNameHeader(),
                        ContextConstants.TENANT_ID_HEADER, ContextUtil.getTenantId(),
                        ContextConstants.USER_ID_HEADER, ContextUtil.getUserId(),
                        elapsed, now, url, sql.replaceAll(REGX, StringPool.SPACE)) :
                StringPool.EMPTY;
    }
}
```

:::

## 将p6spy打印在控制台的SQL语句改为打印到slf4j

::: code-tabs

@tab spy.properties

```properties
#日志输出到控制台
appender=com.baomidou.mybatisplus.extension.p6spy.StdoutLogger
```

@tab TenantP6SpyLogger

```java
package com.baomidou.mybatisplus.extension.p6spy;

/**
 * 输出 SQL 日志
 *
 * @author hubin
 * @since 2019-02-20
 */
@Slf4j
public class StdoutLogger extends com.p6spy.engine.spy.appender.StdoutLogger {

    @Override
    public void logText(String text) {
        // 打印红色 SQL 日志
        // System.err.println(text);
      	log.info(text);
    }
}
```

:::

## 在XML中编写SQL语句时，如何传递模糊查询(like语句)参数

- xml中自定义sql

    ```xml{7-9}
    <?xml version="1.0" encoding="UTF-8"?>
    <!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd">
    <mapper namespace="top.tangyh.lamp.base.mapper.system.DefUserMapper">
    
        <select id="selectAll" parameterType="map">
            select * from user where 1=1 
            and name like #{keyword, typeHandler=fullLike}     
            and account like #{keyword, typeHandler=leftLike}
            and describe like #{keyword, typeHandler=rightLike}
        </select>
    </mapper>
    ```

- 实际sql

    ```sql
    select * from user where 1=1  
    and name like '%张三%'  
    and account like '%lamp'   
    and describe  like '工作%'
    ```

- 原理
  通过自定义TypeHandler，将传递的参数自动拼接上 % 号。
  
  上面的3个TypeHandler分别是：FullLikeTypeHandler、LeftLikeTypeHandler、RightLikeTypeHandler

## 如何在 SuperMapper 中增加方法

1. 在SuperMapper中定义方法接口   

   ```java{9,19}
   public interface SuperMapper<T> extends BaseMapper<T> {
   
       /**
        * 全量修改所有字段
        *
        * @param entity 实体
        * @return 修改数量
        */
       int updateAllById(@Param(Constants.ENTITY) T entity);
   
       /**
        * 批量插入所有字段
        * <p>
        * 只测试过MySQL！只测试过MySQL！只测试过MySQL！
        *
        * @param entityList 实体集合
        * @return 插入数量
        */
       int insertBatchSomeColumn(List<T> entityList);
   }
   ```

2. 定义 updateAllById 和 insertBatchSomeColumn 方法的动态sql解析器

    ::: code-tabs

    @tab UpdateAllById

    ```java
    @NoArgsConstructor
    public class UpdateAllById extends AlwaysUpdateSomeColumnById {
       
        public UpdateAllById(Predicate<TableFieldInfo> predicate) {
            super(predicate);
        }
       
        @Override
        public String getMethod(SqlMethod sqlMethod) {
            // 自定义 mapper 方法名
            return "updateAllById";
        }
    }
    ```

    @tab InsertBatchSomeColumn

    ```java
    package com.baomidou.mybatisplus.extension.injector.methods;
    
    // 这个类是 mybatis-plus 自带的
    public class InsertBatchSomeColumn extends AbstractMethod {
    
        /**
         * 字段筛选条件
         */
        @Setter
        @Accessors(chain = true)
        private Predicate<TableFieldInfo> predicate;
    
        /**
         * 默认方法名
         */
        public InsertBatchSomeColumn() {
            super("insertBatchSomeColumn");
        }
    
        /**
         * 默认方法名
         *
         * @param predicate 字段筛选条件
         */
        public InsertBatchSomeColumn(Predicate<TableFieldInfo> predicate) {
            super("insertBatchSomeColumn");
            this.predicate = predicate;
        }
    
        /**
         * @param name      方法名
         * @param predicate 字段筛选条件
         * @since 3.5.0
         */
        public InsertBatchSomeColumn(String name, Predicate<TableFieldInfo> predicate) {
            super(name);
            this.predicate = predicate;
        }
    
        @SuppressWarnings("Duplicates")
        @Override
        public MappedStatement injectMappedStatement(Class<?> mapperClass, Class<?> modelClass, TableInfo tableInfo) {
            KeyGenerator keyGenerator = NoKeyGenerator.INSTANCE;
            SqlMethod sqlMethod = SqlMethod.INSERT_ONE;
            List<TableFieldInfo> fieldList = tableInfo.getFieldList();
            String insertSqlColumn = tableInfo.getKeyInsertSqlColumn(true, false) +
                this.filterTableFieldInfo(fieldList, predicate, TableFieldInfo::getInsertSqlColumn, EMPTY);
            String columnScript = LEFT_BRACKET + insertSqlColumn.substring(0, insertSqlColumn.length() - 1) + RIGHT_BRACKET;
            String insertSqlProperty = tableInfo.getKeyInsertSqlProperty(true, ENTITY_DOT, false) +
                this.filterTableFieldInfo(fieldList, predicate, i -> i.getInsertSqlProperty(ENTITY_DOT), EMPTY);
            insertSqlProperty = LEFT_BRACKET + insertSqlProperty.substring(0, insertSqlProperty.length() - 1) + RIGHT_BRACKET;
            String valuesScript = SqlScriptUtils.convertForeach(insertSqlProperty, "list", null, ENTITY, COMMA);
            String keyProperty = null;
            String keyColumn = null;
            // 表包含主键处理逻辑,如果不包含主键当普通字段处理
            if (tableInfo.havePK()) {
                if (tableInfo.getIdType() == IdType.AUTO) {
                    /* 自增主键 */
                    keyGenerator = Jdbc3KeyGenerator.INSTANCE;
                    keyProperty = tableInfo.getKeyProperty();
                    keyColumn = tableInfo.getKeyColumn();
                } else {
                    if (null != tableInfo.getKeySequence()) {
                        keyGenerator = TableInfoHelper.genKeyGenerator(this.methodName, tableInfo, builderAssistant);
                        keyProperty = tableInfo.getKeyProperty();
                        keyColumn = tableInfo.getKeyColumn();
                    }
                }
            }
            String sql = String.format(sqlMethod.getSql(), tableInfo.getTableName(), columnScript, valuesScript);
            SqlSource sqlSource = languageDriver.createSqlSource(configuration, sql, modelClass);
            return this.addInsertMappedStatement(mapperClass, modelClass, getMethod(sqlMethod), sqlSource, keyGenerator, keyProperty, keyColumn);
        }
    
    }
    ```

    :::

3. 注入UpdateAllById和InsertBatchSomeColumn

    ```java{7-10}
    public class LampSqlInjector extends DefaultSqlInjector {
        @Override
        public List<AbstractMethod> getMethodList(Class<?> mapperClass, TableInfo tableInfo) {
            List<AbstractMethod> methodList = super.getMethodList(mapperClass, tableInfo);
    
            //增加自定义方法
            methodList.add(new InsertBatchSomeColumn(i -> i.getFieldFill() != FieldFill.UPDATE));
            methodList.add(new UpdateAllById(field -> !ArrayUtil.containsAny(new String[]{
                    SuperEntity.CREATED_TIME_FIELD, SuperEntity.CREATED_BY_FIELD
            }, field.getColumn())));
            return methodList;
        }
    }
    ```

4. 配置 LampSqlInjector ，使他注入SpringBoot容器

    ```java
    @Bean
    @ConditionalOnMissingBean
    public LampSqlInjector getMySqlInjector() {
        return new LampSqlInjector();
    }
    ```

## 配置雪花id规则

```yaml
lamp:
  database: 
    id-type: HU_TOOL   # HU_TOOL、 DEFAULT、CACHE
    hutoolId:     # id-type = HU_TOOL时， 生效
    	# 终端ID (0-31)      单机配置0 即可。 集群部署，根据情况每个实例自增即可。
      workerId: 0
      # 数据中心ID (0-31)   单机配置0 即可。 集群部署，根据情况每个实例自增即可。
      dataCenterId: 0
    # id生成策略 = DEFAULT时，配置项。参数说明参考：https://github.com/baidu/uid-generator
    default-id:    # id-type = DEFAULT， 生效
      time-bits: 31
      worker-bits: 22
      seq-bits: 10
    # id生成策略 = CACHE时，配置项。
    cache-id:     # id-type = CACHE， 生效
    	# 当前时间，相对于时间基点"${epochStr}"的增量值，单位：秒，
      time-bits: 31
      # 机器id
      worker-bits: 22
      # 每秒下的并发序列，13 bits可支持每秒8192个并发，即2^13个并发
      seq-bits: 10
      # 客户历元，单位为秒。可以改成你的项目开始开始的时间
      epochStr: '2020-09-15'
      # RingBuffer size扩容参数, 可提高UID生成的吞吐量.
      boost-power: 3              
      # 指定何时向RingBuffer中填充UID, 取值为百分比(0, 100), 默认为50
      padding-factor: 50
```

## 为什么生成的雪花ID会重复？

- 参考1：[点我](https://blog.csdn.net/u011250186/article/details/125318866)
- 参考2： [点我](https://xie.infoq.cn/article/7f3a0aa802c8c9465f9dee888)
- 参考3： [点我](https://github.com/baidu/uid-generator/blob/master/README.zh_cn.md)

理解了上面几篇文章，应该知道雪花ID的生成跟服务器时间戳，机器ID等参数有关。

灯灯雪花id生成类型有3种： HU_TOOL、DEFAULT、CACHE

- HU_TOOL： 使用hutool 提供的雪花生成算法，集群部署时，需要自行保证每个节点读取到的 `lamp.database.hutoolId.workerId` 或 `lamp.database.hutoolId.dataCenterId` 不一样，==否则很大概率会造成id重复问题== 。
- DEFAULT：UidGenerator通过借用未来时间来解决sequence天然存在的并发限制。
- CACHE（ **推荐使用** ）：采用RingBuffer来缓存已生成的UID, 并行化UID的生产和消费, 同时对CacheLine补齐，避免了由RingBuffer带来的硬件级「伪共享」问题。

其中 DEFAULT、CACHE 就是上文中提到的==百度 Uid==框架，它依赖于 `worker_node ` 表， 工作原理是： 

每次启动项目时，自增一条数据，使用自增id 作为雪花id的 workerId ，避免了集群部署时，动态扩展和缩减节点需要手动配置不同的workerId 的问题。 而CACHE模式，是在DEFAULT模式的基础上做了缓存，性能更好。 

所以集群部署，尤其是需要动态扩容时，强烈建议使用 CACHE 模式。

## id、createTime、createdBy、updateTime、updatedBy 等字段如何自动填充 ？

* 实现元对象处理器接口：top.tangyh.basic.database.datasource.LampMetaObjectHandler
  
  * insert 方法：fill = FieldFill.INSERT 时触发
  
    自动填充 id, createdTime, updatedTime, createdBy, updatedBy 字段，字段为NULL则自动填充，不为空则使用传递进来的
  
  * update 方法：fill = FieldFill.UPDATE 时触发
  
    自动填充 id, updatedTime, updatedBy 字段，字段为NULL则自动填充，不为空则使用传递进来的
  
* 在需要填充的字段标记：  `@TableField(fill = FieldFill.???)` 
  
  ```java
  public class User {
      // 注意！这里需要标记为填充字段   FieldFill.INSERT: 执行insert方法时填充
      @TableField(fill = FieldFill.INSERT)
      private String fillField;
    
      // 注意！这里需要标记为 填充字段  FieldFill.UPDATE: 执行update方法时填充
      @TableField(fill = FieldFill.UPDATE)
      private String fillField2;
  }
  ```

## 主键设置为自增

1. 建议参考[mybatis plus官方文档](https://baomidou.com/pages/568eb2/#spring-boot)

2. `LampMetaObjectHandler` 注释掉调用的 `fillId(metaObject);` 方法
   
   ```java
   @Override
   public void insertFill(MetaObject metaObject) {
       // 注释掉填充id的方法 
       // fillId(metaObject);
   }
   ```

3. 修改 `SuperEntity` 类上的注解
   
   ```java
   // 可选值： 自增=AUTO、 自己控制：INPUT、 跟随全局配置： NONE、  mp提供的雪花Id:ASSIGN_ID
   @TableId(value = "id", type = IdType.AUTO)
   ```

4. 修改 `database.yml` 配置文件 （lamp-boot在application.yml）
   
   ```yaml
   mybatis-plus:
     global-config:
       db-config:
         id-type: INPUT   # 这里的可选值跟上一步一样。 
   ```

5. 将lamp_base、lamp_extend、lamp_defaults 数据库中表的主键id设置为自增

## 不想继承 SuperEntity 、 Entity、 TreeEntity

最好的方式是，已经实现的功能实体类的父类仍然继承 `SuperEntity` 、 `Entity`、 `TreeEntity`，新增的业务代码使用自己新建的父类实体，或者不继承任何父类实体。这样子改动最小！

### 不继承任何实体

1. 手写实体类：让自己的创建的实体不继承任何父类
2. 代码生成器生成实体类：==父类实体==字段选择：NONE

### 继承自己创建的父类实体

1. 手写实体类：让自己的实体类 继承自建的父类即可。

2. 代码生成器：需要在 `EntitySuperClassEnum` 类中新增一个枚举值， 并在生成代码时，"父类实体" 字段选择： MODEL
   
   ```java
   public enum EntitySuperClassEnum {
       // 参数1：自建父类全名    参数2：自建父类的公共字段
       MODEL("com.tangyh.basic.base.entity.Model", new String[]{"id"}),
   }
   ```

## 调用保存方法后，如何获取实体的id

```java
User user = new User();
userService.save(user);
// 在执行save方法后， user的id会被自动赋值
Long id = user.getId();
```

## mybaits的xml配置文件存放路径

灯灯项目将Mbatis相关的XML文件放在lamp-xxx-biz/src/main/resources，有些项目喜欢将xml和mapper都存放在src/main/java里面，其实存放在那里都行，但作者的习惯src/main/java存放的应该是java类，src/main/resources存放的应该是配置文件。

但将xml放在resources文件夹下时，需要在pom.xml中加入如下配置：

```xml{6}
<build>
    <finalName>${project.artifactId}</finalName>
    <resources>
        <resource>
          	<!-- 指定将src/main/resources文件下的配置文件也打入jar -->
            <directory>src/main/resources</directory>
            <includes>
                <include>**/*</include>
            </includes>
            <filtering>true</filtering>
        </resource>
        <resource>
            <directory>src/main/java</directory>
            <includes>
                <include>**/*.xml</include>
            </includes>
            <filtering>true</filtering>
        </resource>
    </resources>
<build>
```

## 为什么要在lamp-xxx-biz/src/main/resources下面新增 mapper_xxx 文件夹？

早期单体项目中，为了降低耦合，一个服务会包含 lamp-xxx-biz、lamp-yyy-biz 等多个业务层，每个业务层都可能存在xml配置。

由于早期的mybatis 版本存在一个bug，若 lamp-xxx-biz 和 lamp-yyy-biz 模块中存放xml的文件夹同名，如 xml 都存放在  lamp-xxx-biz 和 lamp-yyy-biz 模块的`src/main/resources/mapper`  中，运行sql时会报错。

当然，现在新版本的mybatis好像已经修复了这个bug，所以你可以将mapper_xxx文件夹都重命名为mapper。



## 为什么要在lamp-xxx-biz/src/main/resources下面新增 mapper_xxx 文件夹下区分base和ext文件夹？

base文件夹下存放的是代码生成器生成出来的原始XML文件，ext文件夹下存放的是自己写的XML文件，后期发生表结构改变时，方面重新生成代码，新生成的xml文件直接覆盖base文件夹下的文件即可。

一个Mapper类，可以对应多个xml，只要保证xml中namespace和Mapper的全路径一致即可！如：

- BasePositionMapper.java

```java
package top.tangyh.lamp.base.dao.user;
public interface BasePositionMapper extends SuperMapper<BasePosition> {
}
```

- mapper_system/base/BasePositionMapper.xml

```xml{3}
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd">
<mapper namespace="top.tangyh.lamp.base.dao.user.BasePositionMapper">
</mapper>
```

- mapper_system/ext/BasePositionMapper.xml

```xml{3}
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd">
<mapper namespace="top.tangyh.lamp.base.dao.user.BasePositionMapper">
</mapper>
```

## mybatis-plus配置

更多 mytabis plus 配置参考 [官方文档](https://mp.baomidou.com/)。

```yaml
# database.yml
mybatis-plus:
  mapper-locations:  
    - classpath*:mapper_**/**/*Mapper.xml
  typeAliasesPackage: top.tangyh.lamp.*.entity;top.tangyh.basic.database.mybatis.typehandler 
  typeEnumsPackage: top.tangyh.lamp.*.enumeration
  global-config:
    db-config:
      id-type: INPUT
      insert-strategy: NOT_NULL
      update-strategy: NOT_NULL
      where-strategy: NOT_EMPTY
  configuration:
    #配置返回数据库(column下划线命名&&返回java实体是驼峰命名)，自动匹配无需as（没开启这个，SQL需要写as： select user_id as userId）
    map-underscore-to-camel-case: true
    cache-enabled: false
    #配置JdbcTypeForNull, oracle数据库必须配置
    jdbc-type-for-null: 'null'
```

- mapper-locations： 只扫描这个路径下的 mapper.xml
- typeAliasesPackage： MyBaits 别名包扫描路径，通过该属性可以给包中的类注册别名，注册后在 Mapper 对应的 XML 文件中可以直接使用类名，而不用使用全限定的类名(即 XML 中调用的时候不用包含包名)
- typeEnumsPackage： 枚举类 扫描路径，如果配置了该属性，会将路径下的枚举类进行注入，让实体类字段能够简单快捷的使用枚举属性
- db-config.idType:  全局默认主键类型
- db-config.insert-strategy:  字段验证策略之 insert,在 insert 的时候的字段验证策略
- db-config.update-strategy:   字段验证策略之 update,在 update 的时候的字段验证策略
- db-config.where-strategy:  字段验证策略之 where,在 where 的时候的字段验证策略

## druid监控页面

```yaml
spring:
  datasource:
	  druid:
      enable: true
      stat-view-servlet:  #展示Druid的统计信息,StatViewServlet的用途包括：1.提供监控信息展示的html页面2.提供监控信息的JSON API
        enabled: true
         # 根据配置中的url-pattern来访问内置监控页面，内置监控页面的首页是/druid/index.html。例如：http://127.0.0.1:9000/druid/index.html
        url-pattern: /druid/*  
        #允许清空统计数据
        reset-enable: true   
        # 账号密码
        login-username: ''
        login-password: ''
        # 允许访问IP
        allow: ''
```

## 分页插件配置

```yaml
lamp:
  databse:
		# 单页分页条数限制：每次最多查询多少条数据，-1表示不限制
    maxLimit: -1
    # 溢出总页数后是否进行处理：假设总数据只有10页，当你查询第11页以后的数据时，默认设置为查询第一页的数据
    overflow: true
    # 生成 countSql 优化掉 join, 现在只支持 left join
    optimizeJoin: true
```

